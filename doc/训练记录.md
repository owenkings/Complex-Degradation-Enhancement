# 实验记录

## 环境配置 (Mamba 修复)
由于预编译包与 PyTorch 版本不兼容，需从源码编译安装 `mamba_ssm`：
```bash
# 1. 确保 PyTorch 版本正确
pip install "torch==2.3.0+cu121" --index-url https://download.pytorch.org/whl/cu121

# 2. 安装因果卷积依赖
pip install causal_conv1d==1.6.0

# 3. 源码编译安装 mamba_ssm (禁用构建隔离和二进制包)
pip install mamba_ssm==2.3.0 --no-binary mamba_ssm --no-build-isolation
```

## 任务一 (图像增强与分类)

### 1. 数据加载验证
在开始训练前，验证 CUB-C 数据集是否正常：

### 2. 模型训练 (Step 1)
使用 CUB-C 数据集训练/微调 Restormer 模型。
```bash
python -u task1/train_task1.py \
  --data-root data/CUB-C \
  --corruption all \
  --val-split test \
  --epochs 35 \
  --batch-size 2 \
  --accum-steps 8 \
  --amp \
  --lr 5e-5 \
  --print-every 10 \
  --save-dir task1/checkpoints \
  --log-path task1/logs/train_log.csv \
  --pretrained Restormer/Motion_Deblurring/pretrained_models/motion_deblurring.pth
```
- **输出**：训练日志 `task1/logs/train_log.csv`，模型权重保存在 `task1/checkpoints`。

### 3. 结果绘图 (Step 1)
训练完成后，绘制 Loss 曲线及验证集 PSNR/SSIM 变化图。
```bash
python task1/plot_task1_loss.py \
  --log-path task1/logs/train_log.csv \
  --out-path task1/plots/loss_curve.png
```
- **输出**：`loss_curve.png` 图片文件。

### 4. 评估与测试 (Step 2)
在 ImageNet-Val-C 上评估模型性能。该步骤同时完成：
1. **图像增强**：使用训练好的 Restormer 对降质图像进行增强。
2. **质量评估**：计算增强图像与清晰图像的 PSNR 和 SSIM。
3. **分类测试**：将增强后的图像输入 VGG16 网络，计算 Top-1/Top-5 分类精度。

```bash
python task1/eval_task1_imagenetc_vgg16.py \
  --data-root data/ImageNet-C \
  --synset-mapping data/ImageNet-C/synset_mapping.txt \
  --ckpt task1/checkpoints/restormer_best.pth \
  --save-json task1/logs/task1_imagenetc_results.json \
  --corruption "all" \
  --severity "flat" \
  --batch-size 32 \
  --num-workers 8
```
- **参数说明**：
  - `--corruption`: 指定测试的降质类型 (如 `fog,motion_blur` 或 `all`)。
  - `--severity`: 指定测试强度等级，若数据集为扁平结构请使用 `flat`。
- **输出**：
  - 控制台实时输出每组数据的 Accuracy, PSNR, SSIM。
  - 详细结果保存在 `task1/logs/task1_imagenetc_results.json` (**重要**：后续对比需要此文件)。

## 任务二 (基于 Mamba 的特征增强)

### 1. 训练 Feature Enhancer
训练 Mamba 增强模块，使其在 VGG 浅层特征空间将降质特征对齐到清晰特征，并加入语义一致性蒸馏损失。
```bash
python task2/train_task2.py \
  --data-root data/CUB-C \
  --batch-size 8 \
  --num-workers 4 \
  --epochs 120 \
  --lr 1e-4 \
  --lr-scheduler cosine \
  --lr-min 1e-6 \
  --save-dir task2/checkpoints \
  --alpha-kl 0.1 \
  --temperature 2.0 \
  --beta-ce 0.0
```
- **输出**：模型权重保存在 `task2/checkpoints`。
- **训练日志**：`task2/checkpoints/train_log.csv`，包含 MSE/KL/(CE)/Total。

### 2. 评估 (ImageNet-C)
在 ImageNet-Val-C 上测试特征增强效果。
流程：降质图像 -> VGG浅层 -> Mamba Enhancer -> VGG深层 -> 分类结果。
```bash
python task2/eval_task2.py \
  --data-root data/ImageNet-C \
  --dataset-type imagenet-c \
  --synset-mapping data/ImageNet-C/synset_mapping.txt \
  --enhancer-path task2/checkpoints/mamba_enhancer_best.pth \
  --corruption "all" \
  --batch-size 16 \
  --num-workers 8
```

## 任务三 (附加题：特征解码)

### 1. 训练解码器
训练一个 Decoder，将 VGG 浅层特征还原为 RGB 图像（PixelShuffle 上采样 + 感知损失）。
```bash
python task3/train_decoder.py \
  --data-root data/CUB-C \
  --corruption origin \
  --batch-size 16 \
  --num-workers 8 \
  --epochs 120 \
  --lr 2e-4 \
  --lr-scheduler cosine \
  --lr-min 1e-6 \
  --save-dir task3/checkpoints \
  --lambda-perc 0.1
```

### 2. 联合推理与可视化
结合 Task 2 的特征增强器和 Task 3 的解码器，生成最终增强图像。
流程：降质图像 -> VGG浅层 -> Mamba Enhancer -> Decoder -> 增强图像。
```bash
python task3/run_task3.py \
  --data-root data/ImageNet-C \
  --dataset-type imagenet-c \
  --synset-mapping data/ImageNet-C/synset_mapping.txt \
  --enhancer-ckpt task2/checkpoints/mamba_enhancer_best.pth \
  --decoder-ckpt task3/checkpoints/feature_decoder_best.pth \
  --output-dir task3/results \
  --corruption "all" \
  --severity "flat" \
  --batch-size 32 \
  --num-workers 8 \
  --save-results
```
- **输出**：增强后的图像保存在 `task3/results` 目录下。

### 3. 结果对比与汇总 (Comparison)
汇总 Task 1 和 Task 2 的评估数据，生成对比表格和图表。
```bash
python task3/compare_results.py \
  --task1-json task1/logs/task1_imagenetc_results.json \
  --task2-json task2/logs/task2_imagenetc_results.json \
  --out-dir task3/outputs
```
- **输出**：`comparison_summary.csv` 和对比图表，保存在 `task3/outputs`。
