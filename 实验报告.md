# 复杂降质图像感知增强课程设计实验报告

## 1. 摘要
本报告围绕“复杂降质图像感知增强”课程设计，基于当前仓库实现，分别完成图像增强（Task1）、特征增强（Task2）与特征解码（Task3）的训练与评测流程整理，并在不虚构数值的前提下提供复现命令链、结果索引与对比分析模板。结论以定性描述为主，所有指标均需从已有日志/结果文件中读取或保持占位符。

## 2. 任务要求与评价指标（来自任务书）
- Task1：在 CUB-C 上微调/训练 All-in-One 图像增强模型；在 ImageNet-Val-C 上评估增强后图像的 PSNR/SSIM，并通过 VGG16 测试分类精度（Top-1/Top-5）。
- Task2：按 DDP 思路，在 VGG16 浅层特征空间进行基于 Mamba 的特征增强训练；在 ImageNet-Val-C 上评估增强后特征的分类精度，并与 Task1 对比。
- Task3（附加题）：训练 VGG 浅层表征的解码器，将增强后的特征解码回图像；可视化增强效果。
- 报告要求：给出 Loss 曲线、说明实验过程与分工、提交训练代码与模型。

## 3. 数据集与预处理（以代码为准）
### 3.1 CUB-C（训练）
- 结构：`origin/` 与各 `corruption/` 目录（fog/contrast/brightness/motion_blur/snow），且路径与 `origin/` 对齐。
- 元数据：`annotations/images.txt`、`annotations/image_class_labels.txt`、`annotations/train_test_split.txt`。
- Dataset 输出：`(degraded_img, clean_img, label)`。
- 预处理（Task1 训练）：`Resize(256) → CenterCrop(256) → ToTensor()`。
- 预处理（Task2/Task3 训练）：`Resize(256) → CenterCrop(224) → ToTensor() → Normalize(ImageNet)`。

### 3.2 ImageNet-Val-C（评测）
- 结构：`<corruption>/<severity>/<synset>/<image>`；若无 severity 子目录，使用扁平结构 `<corruption>/<synset>/<image>`。
- 需要 `synset_mapping.txt` 将 WNID 映射为类别索引。
- 预处理（Task1/Task2/Task3 评测）：`Resize(256) → CenterCrop(224) → ToTensor()`，Task2/Task3 额外做 ImageNet 标准化。

## 4. 方法设计与动机（对齐当前实现）

### 4.1 Task1：图像增强（Restormer）
动机：直接在图像域提升可视质量，降低降质对分类网络的影响。实现采用 Restormer，对 CUB-C 中的降质图像进行恢复，训练目标为 clean 图像的 L1 损失。验证阶段以 PSNR/SSIM 评估增强质量，并将增强后的图像输入 VGG16 进行识别测试。

### 4.2 Task2：特征增强（VGG SPL + Mamba Enhancer + VGG DPL）
动机：不在图像域修复，而是在 VGG16 浅层特征空间把降质特征对齐到清晰特征。实现中 SPL 固定为 VGG16 的 `relu2_2` 前后层（输出通道 128），Mamba Enhancer 采用双向扫描（正向与反向序列建模）并通过门控残差融合输出。训练监督包括：
- 特征 MSE：对齐 clean 特征
- KL 蒸馏：对齐 clean 特征对应的分类分布
- 可选 CE：由 `beta-ce` 控制（默认关闭）

### 4.3 Task3：浅层特征解码与联合推理
动机：将 Task2 产生的增强特征还原为图像，以提供可视化增强结果。解码器为 PixelShuffle 上采样结构，训练目标为 clean 图像的 L1 + 感知损失（VGGPerceptual）。联合推理链路为：降质图像 → VGG SPL → Mamba Enhancer → Decoder → 增强图像，并可计算 PSNR/SSIM。

## 5. 关键脚本逐条说明（目的 / 思想 / I/O / 命令 / 产物）

### 5.1 task1/train_task1.py（Task1 Step1 训练）
目的：在 CUB-C 上训练或微调 Restormer，获得增强模型并记录 Loss 曲线所需日志。  
关键思想：图像域恢复，优化 L1Loss；可加载 Restormer 预训练权重。  
I/O：输入 `(degraded_img, clean_img, label)`，输出增强图像；日志写入 `train_log.csv`，模型写入 `restormer_best.pth/restormer_latest.pth`。  
建议命令（默认参数）：  
```bash
python task1/train_task1.py \
  --data-root data/CUB-C \
  --corruption all \
  --val-split test \
  --epochs 50 \
  --batch-size 2 \
  --num-workers 4 \
  --lr 5e-5 \
  --accum-steps 1 \
  --save-dir task1/checkpoints \
  --pretrained Restormer/Motion_Deblurring/pretrained_models/motion_deblurring.pth
```
训练记录实际命令：见 [训练记录.md](./训练记录.md) 中“Task1 训练”。  
产物路径：`task1/checkpoints/restormer_best.pth`、`task1/logs/train_log.csv`。

### 5.2 task1/plot_task1_loss.py（Task1 Step1 曲线绘制）
目的：从训练日志绘制 Loss 与 PSNR/SSIM 曲线，满足任务书要求。  
关键思想：读取 `train_log.csv` 的 epoch、train_l1、val_psnr、val_ssim。  
I/O：输入训练日志，输出 `loss_curve.png`。  
建议命令：  
```bash
python task1/plot_task1_loss.py \
  --log-path task1/logs/train_log.csv \
  --out-path task1/plots/loss_curve.png
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task1/plots/loss_curve.png`。

### 5.3 task1/eval_task1_imagenetc_vgg16.py（Task1 Step2 评测）
目的：在 ImageNet-Val-C 上评估增强效果与分类精度。  
关键思想：Restormer 生成增强图像；计算 PSNR/SSIM；将原图与增强图分别输入 VGG16 计算 Top-1/Top-5。  
I/O：输入 ImageNet-C 样本与 synset_mapping，输出 json 结果。  
建议命令（默认参数）：  
```bash
python task1/eval_task1_imagenetc_vgg16.py \
  --data-root data/ImageNet-C \
  --ckpt task1/checkpoints/restormer_best.pth \
  --corruption "fog,snow,brightness,contrast,motion_blur" \
  --severity flat \
  --batch-size 32 \
  --num-workers 4 \
  --save-json task1/logs/task1_imagenetc_results.json \
  --synset-mapping data/ImageNet-C/synset_mapping.txt
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task1/logs/task1_imagenetc_results.json`。

### 5.4 task2/train_task2.py（Task2 Step1 训练）
目的：在 VGG16 浅层特征空间训练 Mamba Enhancer，对齐 clean 特征并保持语义一致性。  
关键思想：SPL 固定，Mamba Enhancer 学习特征残差；损失为 MSE + KL 蒸馏 + 可选 CE。  
I/O：输入 `(degraded_img, clean_img, label)`，输出增强特征；保存 best/last 模型与训练日志。  
建议命令（默认参数）：  
```bash
python task2/train_task2.py \
  --data-root data/CUB-C \
  --corruption all \
  --val-corruption "fog,contrast,brightness,motion_blur,snow" \
  --epochs 20 \
  --batch-size 32 \
  --num-workers 4 \
  --lr 1e-4 \
  --lr-scheduler cosine \
  --lr-min 0.0 \
  --save-dir task2/checkpoints \
  --alpha-kl 0.1 \
  --temperature 2.0 \
  --beta-ce 0.0
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task2/checkpoints/mamba_enhancer_best_top1.pth`、`task2/checkpoints/train_log.csv`。

### 5.5 task2/eval_task2.py（Task2 Step2 评测）
目的：在 ImageNet-Val-C 上评估特征增强对分类的影响。  
关键思想：SPL→(Enhancer)→DPL；默认同时评估 baseline 与 enhanced。  
I/O：输入 ImageNet-C 与 synset_mapping，输出 `task2_imagenetc_results.json` 与 baseline 版本。  
建议命令（默认参数）：  
```bash
python task2/eval_task2.py \
  --data-root data/ImageNet-C \
  --dataset-type imagenet-c \
  --enhancer-path task2/checkpoints/mamba_enhancer_best.pth \
  --corruption all \
  --severity flat \
  --batch-size 32 \
  --num-workers 4 \
  --save-json task2/logs/task2_imagenetc_results.json \
  --save-json-baseline task2/logs/task2_imagenetc_results_baseline.json \
  --synset-mapping data/ImageNet-C/synset_mapping.txt
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task2/logs/task2_imagenetc_results.json`、`task2/logs/task2_imagenetc_results_baseline.json`。

### 5.6 task3/train_decoder.py（Task3 Step1 训练）
目的：训练特征解码器，将 VGG 浅层特征还原为图像。  
关键思想：L1 + 感知损失（VGGPerceptual），输出通过 PixelShuffle 上采样。  
I/O：输入 clean 图像，经 VGG SPL 提取特征，输出重建图像与训练日志。  
建议命令（默认参数）：  
```bash
python task3/train_decoder.py \
  --data-root data/CUB-C \
  --corruption origin \
  --epochs 20 \
  --batch-size 32 \
  --num-workers 4 \
  --lr 1e-3 \
  --lr-scheduler cosine \
  --lr-min 0.0 \
  --save-dir task3/checkpoints \
  --lambda-perc 0.1
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task3/checkpoints/feature_decoder_best.pth`、`task3/checkpoints/logs/task3_train_log_*.csv`。

### 5.7 task3/run_task3.py（Task3 Step2 联合推理）
目的：将 Task2 增强特征解码回图像并保存可视化对比。  
关键思想：降质图像 → VGG SPL → Mamba Enhancer → Decoder → 增强图像；计算 PSNR/SSIM。  
I/O：输入 ImageNet-C/CUB-C 与两个 ckpt，输出对比图 `comparison_*.png`。  
建议命令（默认参数）：  
```bash
python task3/run_task3.py \
  --data-root data/CUB-C \
  --dataset-type cub-c \
  --corruption fog \
  --severity flat \
  --enhancer-ckpt task2/checkpoints/mamba_enhancer_best.pth \
  --decoder-ckpt task3/checkpoints/feature_decoder_best.pth \
  --batch-size 16 \
  --num-workers 4 \
  --output-dir task3/results
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task3/results/comparison_{dataset_type}_{corruption}_sev-{severity}_N-{max_samples}.png`。

### 5.8 task3/compare_results.py（Task1 vs Task2 对比）
目的：汇总 Task1/Task2 的评测结果并输出对比表格与图表。  
关键思想：读取两份 json，统一字段并输出 csv/png。  
I/O：输入两份结果 json，输出 `comparison_summary.csv` 与对比图。  
建议命令（默认参数）：  
```bash
python task3/compare_results.py \
  --task1-json task1/logs/task1_imagenetc_results.json \
  --task2-json task2/logs/task2_imagenetc_results.json \
  --output-dir task3/comparison_results
```
训练记录实际命令：见 [训练记录.md](./训练记录.md)。  
产物路径：`task3/outputs/comparison_summary.csv`、`task3/outputs/accuracy_comparison_bar.png`。

## 6. 实验设置
- 硬件：【待填：GPU 型号/显存】、【待填：CPU】、【待填：内存】
- 软件环境：Python【待填】；PyTorch 版本见 `requirements.txt`；CUDA【待填】
- 固定随机种子：2025（脚本内设置）
- 关键超参：以 [训练记录.md](./训练记录.md) 的命令为准

## 7. 复现流程（命令链）
1. Task1 训练 → Task1 曲线绘制 → Task1 评测  
2. Task2 训练 → Task2 评测（baseline + enhanced）  
3. Task3 训练 → Task3 联合推理 → Task1/Task2 对比汇总  
完整命令链与输入/输出路径见 [训练记录.md](./训练记录.md)。

## 8. 结果汇总（不填写数值）
以下表格只提供占位符，并标注可从何处读取真实数值。

| Corruption | Task1 Top-1 Degraded | Task1 Top-1 Restored | Task1 PSNR | Task1 SSIM | Task2 Top-1 Enhanced | Task2 Top-1 Baseline |
|---|---|---|---|---|---|---|
| fog | 0.3411 | 0.5369 | 21.4906 | 0.8412 | 0.5385 | 0.3411 |
| contrast | 0.2708 | 0.4708 | 28.6316 | 0.8764 | 0.4775 | 0.2708 |
| brightness | 0.5743 | 0.6157 | 26.7925 | 0.8944 | 0.6150 | 0.5743 |
| motion_blur | 0.2597 | 0.4913 | 31.1609 | 0.8917 | 0.4354 | 0.2597 |
| snow | 0.2226 | 0.5265 | 26.6957 | 0.8512 | 0.4647 | 0.2226 |

指标来源：
- Task1：`../task1/logs/task1_imagenetc_results.json` 的 `results[].top1_degraded/top1_restored/psnr/ssim`
- Task2：`../task2/logs/task2_imagenetc_results.json` 的 `results[].top1`
- Task2 基线：`../task2/logs/task2_imagenetc_results_baseline.json` 的 `results[].top1`

## 9. 对比分析模板（Task1 vs Task2）
用于填写对比分析的模板，数值请从结果文件读取。

| Corruption | Task1 Top-1 Restored | Task2 Top-1 Enhanced | 差异描述 |
|---|---|---|---|
| fog | 0.5369 | 0.5385 | 【待填：定性结论】 |
| contrast | 0.4708 | 0.4775 | 【待填：定性结论】 |
| brightness | 0.6157 | 0.6150 | 【待填：定性结论】 |
| motion_blur | 0.4913 | 0.4354 | 【待填：定性结论】 |
| snow | 0.5265 | 0.4647 | 【待填：定性结论】 |

数值来源：
- Task1：`../task1/logs/task1_imagenetc_results.json` 的 `results[].top1_restored`
- Task2：`../task2/logs/task2_imagenetc_results.json` 的 `results[].top1`

可视化解释（Task3）：
- 对比图保存于 `task3/results/comparison_*.png`，用于解释特征增强后的图像外观变化（仅做定性分析）。

## 10. 结论与不足
- Task1 的图像增强可直接改善图像质量并提升识别稳定性，但成本较高（像素级推理）。  
- Task2 的特征增强更轻量，可直接插入分类网络，但其效果依赖于浅层特征对齐质量。  
- Task3 提供可视化解释，但解码器能力受限于浅层特征信息量。  
- 不足与改进方向：可尝试更强的增强模块、更丰富的蒸馏损失与多尺度特征解码。

## 11. 小组成员分工
- 【待填：成员 A】—【待填：分工】  
- 【待填：成员 B】—【待填：分工】  
- 【待填：成员 C】—【待填：分工】  

## 12. 附录

### 12.1 产物清单（提交清单）
- Task1：`task1/checkpoints/restormer_best.pth`、`task1/logs/train_log.csv`、`task1/plots/loss_curve.png`、`task1/logs/task1_imagenetc_results.json`
- Task2：`task2/checkpoints/mamba_enhancer_best_top1.pth`、`task2/logs/task2_imagenetc_results.json`、`task2/logs/task2_imagenetc_results_baseline.json`
- Task3：`task3/checkpoints/feature_decoder_best.pth`、`task3/outputs/comparison_summary.csv`、`task3/outputs/accuracy_comparison_bar.png`、`task3/outputs/task1_quality_metrics.png`
- 报告：`doc/实验报告.md`、`doc/训练记录.md`

### 12.2 脚本入口索引
- [train_task1.py](../task1/train_task1.py)
- [plot_task1_loss.py](../task1/plot_task1_loss.py)
- [eval_task1_imagenetc_vgg16.py](../task1/eval_task1_imagenetc_vgg16.py)
- [train_task2.py](../task2/train_task2.py)
- [eval_task2.py](../task2/eval_task2.py)
- [mamba_enhancer.py](../task2/mamba_enhancer.py)
- [vgg_feature_wrapper.py](../task2/vgg_feature_wrapper.py)
- [train_decoder.py](../task3/train_decoder.py)
- [decoder.py](../task3/decoder.py)
- [run_task3.py](../task3/run_task3.py)
- [compare_results.py](../task3/compare_results.py)
- [dataset.py](../utils/dataset.py)
- [metrics.py](../utils/metrics.py)
